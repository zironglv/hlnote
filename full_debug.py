#!/usr/bin/env python3
"""
å®Œæ•´çš„é¡¹ç›®è°ƒè¯•è„šæœ¬ - å…¨é¢æ£€æŸ¥é¡¹ç›®çŠ¶æ€
"""

import sys
import os
import logging
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def check_file_structure():
    """æ£€æŸ¥é¡¹ç›®æ–‡ä»¶ç»“æ„"""
    logger.info("ğŸ” æ£€æŸ¥é¡¹ç›®æ–‡ä»¶ç»“æ„...")
    
    required_files = [
        'main_multi_fixed.py',
        'multi_index_analyzer.py', 
        'index_config.py',
        'data_collector.py',
        'data_processor.py',
        'report_generator.py',
        'dingtalk_sender.py',
        'requirements.txt'
    ]
    
    missing_files = []
    for file_name in required_files:
        if os.path.exists(file_name):
            logger.info(f"âœ… {file_name}")
        else:
            logger.error(f"âŒ ç¼ºå°‘æ–‡ä»¶: {file_name}")
            missing_files.append(file_name)
    
    return len(missing_files) == 0

def check_dependencies():
    """æ£€æŸ¥Pythonä¾èµ–"""
    logger.info("ğŸ” æ£€æŸ¥Pythonä¾èµ–...")
    
    required_packages = [
        'pandas',
        'matplotlib',
        'requests',
        'numpy',
        'openpyxl'
    ]
    
    missing_packages = []
    for package in required_packages:
        try:
            __import__(package)
            logger.info(f"âœ… {package}")
        except ImportError:
            logger.error(f"âŒ ç¼ºå°‘ä¾èµ–åŒ…: {package}")
            missing_packages.append(package)
    
    return len(missing_packages) == 0

def test_data_collection():
    """æµ‹è¯•æ•°æ®æ”¶é›†åŠŸèƒ½"""
    logger.info("ğŸ” æµ‹è¯•æ•°æ®æ”¶é›†åŠŸèƒ½...")
    
    try:
        sys.path.append(os.path.dirname(os.path.abspath(__file__)))
        from data_collector import DataCollector
        
        collector = DataCollector()
        # æµ‹è¯•è·å–çº¢åˆ©ä½æ³¢æŒ‡æ•°æ•°æ®
        test_url = "https://oss-ch.csindex.com.cn/static/html/csindex/public/uploads/file/autofile/indicator/H30269indicator.xls"
        data = collector.fetch_csv_data(test_url)
        
        if data is not None and len(data) > 0:
            logger.info(f"âœ… æ•°æ®æ”¶é›†æˆåŠŸï¼Œè·å–åˆ° {len(data)} è¡Œæ•°æ®")
            logger.info(f"æ•°æ®åˆ—å: {list(data.columns)[:5]}")  # æ˜¾ç¤ºå‰5åˆ—
            return True
        else:
            logger.error("âŒ æ•°æ®æ”¶é›†å¤±è´¥ï¼šè¿”å›ç©ºæ•°æ®")
            return False
            
    except Exception as e:
        logger.error(f"âŒ æ•°æ®æ”¶é›†æµ‹è¯•å¼‚å¸¸: {str(e)}")
        return False

def test_data_processing():
    """æµ‹è¯•æ•°æ®å¤„ç†åŠŸèƒ½"""
    logger.info("ğŸ” æµ‹è¯•æ•°æ®å¤„ç†åŠŸèƒ½...")
    
    try:
        sys.path.append(os.path.dirname(os.path.abspath(__file__)))
        from data_collector import DataCollector
        from data_processor import DataProcessor
        
        # å…ˆè·å–æ•°æ®
        collector = DataCollector()
        test_url = "https://oss-ch.csindex.com.cn/static/html/csindex/public/uploads/file/autofile/indicator/H30269indicator.xls"
        raw_data = collector.fetch_csv_data(test_url)
        
        # å¤„ç†æ•°æ®
        processor = DataProcessor()
        processed_data = processor.analyze_data(raw_data)
        
        if processed_data and 'metrics' in processed_data:
            metrics = processed_data['metrics']
            logger.info("âœ… æ•°æ®å¤„ç†æˆåŠŸ")
            logger.info(f"å½“å‰è‚¡æ¯ç‡: {metrics.get('current_rate', 'N/A')}")
            logger.info(f"15æ—¥å¹³å‡: {metrics.get('avg_15d', 'N/A')}")
            logger.info(f"æŠ•èµ„å»ºè®®: {metrics.get('investment_advice', {}).get('action', 'N/A')}")
            return True
        else:
            logger.error("âŒ æ•°æ®å¤„ç†å¤±è´¥ï¼šæœªç”Ÿæˆæœ‰æ•ˆæŒ‡æ ‡")
            return False
            
    except Exception as e:
        logger.error(f"âŒ æ•°æ®å¤„ç†æµ‹è¯•å¼‚å¸¸: {str(e)}")
        return False

def test_report_generation():
    """æµ‹è¯•æŠ¥å‘Šç”ŸæˆåŠŸèƒ½"""
    logger.info("ğŸ” æµ‹è¯•æŠ¥å‘Šç”ŸæˆåŠŸèƒ½...")
    
    try:
        sys.path.append(os.path.dirname(os.path.abspath(__file__)))
        from data_collector import DataCollector
        from data_processor import DataProcessor
        from report_generator import ReportGenerator
        
        # è·å–å¹¶å¤„ç†æ•°æ®
        collector = DataCollector()
        processor = DataProcessor()
        generator = ReportGenerator()
        
        test_url = "https://oss-ch.csindex.com.cn/static/html/csindex/public/uploads/file/autofile/indicator/H30269indicator.xls"
        raw_data = collector.fetch_csv_data(test_url)
        processed_data = processor.analyze_data(raw_data)
        
        # ç”ŸæˆæŠ¥å‘Š
        html_content, chart_path = generator.generate_report(processed_data)
        
        if html_content and len(html_content) > 100:  # ç®€å•æ£€æŸ¥æŠ¥å‘Šé•¿åº¦
            logger.info("âœ… æŠ¥å‘Šç”ŸæˆæˆåŠŸ")
            logger.info(f"HTMLé•¿åº¦: {len(html_content)} å­—ç¬¦")
            if chart_path and os.path.exists(chart_path):
                logger.info(f"å›¾è¡¨ç”ŸæˆæˆåŠŸ: {chart_path}")
            return True
        else:
            logger.error("âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼šå†…å®¹è¿‡çŸ­æˆ–ä¸ºç©º")
            return False
            
    except Exception as e:
        logger.error(f"âŒ æŠ¥å‘Šç”Ÿæˆæµ‹è¯•å¼‚å¸¸: {str(e)}")
        return False

def test_multi_index_analysis():
    """æµ‹è¯•å¤šæŒ‡æ•°åˆ†æåŠŸèƒ½"""
    logger.info("ğŸ” æµ‹è¯•å¤šæŒ‡æ•°åˆ†æåŠŸèƒ½...")
    
    try:
        sys.path.append(os.path.dirname(os.path.abspath(__file__)))
        from multi_index_analyzer import MultiIndexAnalyzer
        from index_config import index_manager
        
        # è·å–æ‰€æœ‰æŒ‡æ•°é…ç½®
        indexes = index_manager.get_all_indexes()
        logger.info(f"é…ç½®çš„æŒ‡æ•°æ•°é‡: {len(indexes)}")
        
        # åˆ›å»ºåˆ†æå™¨ï¼ˆä¸å‘é€é’‰é’‰æ¶ˆæ¯ï¼‰
        analyzer = MultiIndexAnalyzer(indexes, send_summary=False)
        
        # æ‰§è¡Œåˆ†æ
        results, send_results = analyzer.run_full_analysis()
        
        success_count = sum(1 for r in results if r.success)
        logger.info(f"âœ… å¤šæŒ‡æ•°åˆ†æå®Œæˆ: {success_count}/{len(indexes)} ä¸ªæŒ‡æ•°åˆ†ææˆåŠŸ")
        
        for result in results:
            status = "âœ“" if result.success else "âœ—"
            logger.info(f"{status} {result.index_config.name}")
            if not result.success:
                logger.error(f"  é”™è¯¯è¯¦æƒ…: {result.error_message}")
        
        return success_count > 0  # è‡³å°‘æœ‰ä¸€ä¸ªæˆåŠŸå°±ç®—é€šè¿‡
        
    except Exception as e:
        logger.error(f"âŒ å¤šæŒ‡æ•°åˆ†ææµ‹è¯•å¼‚å¸¸: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def check_github_actions_config():
    """æ£€æŸ¥GitHub Actionsé…ç½®"""
    logger.info("ğŸ” æ£€æŸ¥GitHub Actionsé…ç½®...")
    
    workflow_files = [
        '.github/workflows/ai-investment-assistant.yml',
        '.github/workflows/minimal_test.yml'
    ]
    
    config_ok = True
    for workflow_file in workflow_files:
        if os.path.exists(workflow_file):
            logger.info(f"âœ… {workflow_file}")
        else:
            logger.warning(f"âš ï¸ ç¼ºå°‘å·¥ä½œæµæ–‡ä»¶: {workflow_file}")
            config_ok = False
    
    # æ£€æŸ¥å…³é”®é…ç½®é¡¹
    main_workflow = '.github/workflows/ai-investment-assistant.yml'
    if os.path.exists(main_workflow):
        with open(main_workflow, 'r', encoding='utf-8') as f:
            content = f.read()
            if 'DINGTALK_WEBHOOK' in content:
                logger.info("âœ… å·¥ä½œæµé…ç½®äº†DINGTALK_WEBHOOK")
            else:
                logger.warning("âš ï¸ å·¥ä½œæµæœªé…ç½®DINGTALK_WEBHOOK")
                config_ok = False
    
    return config_ok

def main():
    """ä¸»è°ƒè¯•å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹å…¨é¢é¡¹ç›®è°ƒè¯•...")
    logger.info(f"è°ƒè¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    tests = [
        ("é¡¹ç›®æ–‡ä»¶ç»“æ„", check_file_structure),
        ("Pythonä¾èµ–", check_dependencies),
        ("æ•°æ®æ”¶é›†åŠŸèƒ½", test_data_collection),
        ("æ•°æ®å¤„ç†åŠŸèƒ½", test_data_processing),
        ("æŠ¥å‘Šç”ŸæˆåŠŸèƒ½", test_report_generation),
        ("å¤šæŒ‡æ•°åˆ†æåŠŸèƒ½", test_multi_index_analysis),
        ("GitHub Actionsé…ç½®", check_github_actions_config)
    ]
    
    passed_tests = 0
    total_tests = len(tests)
    
    print("\n" + "="*60)
    print("ğŸ“Š é¡¹ç›®è°ƒè¯•ç»“æœ")
    print("="*60)
    
    for test_name, test_func in tests:
        try:
            print(f"\nğŸ” æ­£åœ¨æµ‹è¯•: {test_name}")
            if test_func():
                passed_tests += 1
                print(f"âœ… {test_name} - é€šè¿‡")
            else:
                print(f"âŒ {test_name} - å¤±è´¥")
        except Exception as e:
            print(f"âŒ {test_name} - å¼‚å¸¸: {str(e)}")
    
    print("\n" + "="*60)
    print(f"ğŸ¯ è°ƒè¯•æ€»ç»“: {passed_tests}/{total_tests} é¡¹æµ‹è¯•é€šè¿‡")
    print("="*60)
    
    if passed_tests == total_tests:
        print("ğŸ‰ æ­å–œï¼æ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡äº†ï¼")
        print("âœ… é¡¹ç›®å¯ä»¥æ­£å¸¸éƒ¨ç½²åˆ°GitHub Actions")
        return 0
    else:
        print("ğŸ’¥ å­˜åœ¨é—®é¢˜éœ€è¦ä¿®å¤")
        print("ğŸ“‹ å»ºè®®æ£€æŸ¥ä¸Šè¿°å¤±è´¥çš„æµ‹è¯•é¡¹")
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)